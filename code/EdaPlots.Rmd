---
title: "eda_isolates"
author: "Yifan Zhao"
date: "23/10/2022"
output: pdf_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(knitr)
library(gridExtra)
library(grid)
library(tableone)
library(lubridate) 
library(table1)
library(kableExtra)
library(table1)

setwd('~/downloads/php2550/pda_project')
# isolates <- read.csv('isolates2010plus.csv')
isolates <- read.csv('isolates_filtered_collect_date_imputed.csv')
isolates_cleaned_location <- read.csv('isolates_cleaned_location.csv')
dim(isolates)

```


```{r}
# Function to see distinct values of column
seeCol <- function(col){
  isolates %>% select(col) %>% distinct()
}

src <- seeCol('Isolation.source')
cluster <- seeCol('SNP.cluster')
Virulence.genotypes <- seeCol('Virulence.genotypes')
colldate <- seeCol('Collection.date')
strain <- seeCol('Strain')

AMR.core <- seeCol('AMR.genotypes.core')


# replace with NA
for (i in 1:dim(isolates)[2]) {
  isolates[isolates[,i] %in% c('',' ', '  '), i] <- NA
}
```



```{r}
# number of levels per column
n_dist_values <- sapply(1:dim(isolates)[2], function(x) length(unique(isolates[,x])))
n_missing <- sapply(1:dim(isolates)[2], function(x) sum(is.na(isolates[,x])))
pct_missing <- sapply(1:dim(isolates)[2], function(x) round(sum(is.na(isolates[,x])) / dim(isolates)[1],2))

col_summary <- data.frame(column = names(isolates), n_dist_values, n_missing, pct_missing)

```

# Antimicrobial Resistance (AMR) genotypes:

```{r ExtractGenes}
# 1. extract gene string before =COMPLETE:
extractGene <- function(genestr){
  str_split = unlist(strsplit(genestr,',',fixed=TRUE))
  str_split = str_replace_all(str_split, "[[()-]]", "")

  # extract anything before COMPLETE
  gene_regex <- ".+(?==COMPLETE)"
  str_extracted <- str_extract_all(str_split, gene_regex)
  str_vec = c()
  str_vec = sapply(1: length(str_split), 
                   function(i) str_vec[i] = str_extracted[i])
  return(unlist(str_vec))
}

str1 = 'dfrG=COMPLETE,fosX=COMPLETE,tet(M)=COMPLETE'
str2 = 'abc-f=HMM,fosX=COMPLETE,lin=COMPLETE'
extractGene(str1)
extractGene(str2)

```



```{r}
# Function to add dummy:
geneDummy <- function(col){
  gene_table <- seeCol(col)
  # Add complete gene column:
  for (i in 1:dim(gene_table)[1]){
    gene_table[i,'complete_gene'] <- paste(extractGene(as.character(gene_table[,col][i])), collapse = ',')
  }

  # Create dummy variable for genes:
  core_genes = unique(unlist(strsplit(as.character(gene_table$complete_gene),',',fixed=TRUE)))
  gene_table = cbind(gene_table, sapply(core_genes, function(x) as.integer(grepl(x, gene_table$complete_gene))))
  dim(gene_table)

  isolates_gene_dummy2 <- isolates %>%
    left_join(gene_table, by = col)
  return(isolates_gene_dummy2)
}

# dummy_amr_core <- geneDummy('AMR.genotypes.core')
dummy_amr <- geneDummy('AMR.genotypes')

AMR_idx <- which(names(dummy_amr)=='AMR.genotypes')
dummy_example <- dummy_amr[,c(AMR_idx, (dim(isolates)[2]+1):dim(dummy_amr)[2])] %>% distinct()
head(dummy_example,10) %>% kable()

```


The AMR genes resources are available in the NCBI database and the 'AMR_genotypes' variable stores the AMR genes found in the isolate and corresponding genotype categories, which include complete, hmm, mis-translation, partial and partial end of contig. More information about genotype categories is documented in the NCBI website https://www.ncbi.nlm.nih.gov/pathogens/pathogens_help/#genotype-categories. For the purpose of exploring potential features for the classification model, we converted the AMR_genotypes variable into gene dummy variables and conducted data exploration. We converted all the AMR genes into indicator variables that have value of 1 if certain gene is found as 'COMPLETE' in the isolate. As we further progress in the project, we might consider include dummy variables for genes that have other categories such as partial, hmm, and mistranslation, although it will lead to a higher dimensional data set. 

Table __ demonstrates the frequency of expressed complete AMR genes in the isolate dataset with Listeria monocytogenes pathogen. Gene fosX and lin are found in 99% of the isolate samples, gene tetM is found in 1.9% of the isolates, gene emrC, vanXYC, vanR, dfrG, vanC, and tetS are found in 0.1% ~ 0.2%; genes that are found in less than 0.1% were omitted in the table. Although the observed percentage doesn't seem to differentiate the isolates in the current dataset, we should evaluate the effect concordantly with outcome labels in the future analysis.

```{r}
# EDA for gene variables:
# extract column number for gene indicator:
ind <- which(names(dummy_amr)=='complete_gene') +1
n_complete <- colSums(dummy_amr[,ind:dim(dummy_amr)[2]])
pct_complete <- round(colSums(dummy_amr[,ind:dim(dummy_amr)[2]]) / dim(isolates)[1],4)
gene_summary <- data.frame(n_complete, pct_complete) 
gene_summary <- gene_summary %>% 
  mutate(AMR_gene = rownames(gene_summary)) %>% arrange(desc(n_complete)) %>% filter(pct_complete >= 0.001)

# reorder columns:
gene_summary <- gene_summary[,c('AMR_gene','n_complete', 'pct_complete')]
rownames(gene_summary) <- NULL
kable(gene_summary, caption = 'Complete AMR Genes Frequency') 
```


# By location
```{r}
# Add cleaned location column:
# isolates_cleaned_location <- read.csv('isolates_cleaned_location.csv')
# isolates_cleaned_location <- read.csv('isolates_cleaned_location.csv')
# ind1 <- which(names(isolates_cleaned_location) =='location_new')
# ind2 <- which(names(isolates_cleaned_location) =='Isolate')
# isolates_cleaned_location_sub <- isolates_cleaned_location[,c(ind1, ind2)]
# isolates <- isolates %>% left_join(isolates_cleaned_location_sub, by='Isolate')

# Extract Region and US state level:
isolates <- isolates %>% mutate(region = ifelse(substr(location_new,1,3) =='USA', 'USA', as.character(location_new)),
                                US_state = ifelse(substr(location_new, 1, 3) == 'USA', 
                                            substr(location_new, 5,6), 'unknown'),
                                US_state = ifelse(US_state %in% c('', NA,'unknown'),'unknown', US_state)
                                )
```


US and Europe are the two major source of region in our dataset, as illustrated in Figure __ . Within the 18586 US isolates, 14643 isolates (78.8%) have specific state information available. The distribution by states is shown in the right panel of Figure __ - California and New York have the most reported Listeria isolates, followed by Washington, Pennsylvania and Ohio.  


```{r visualize by region}
byRegiontbl <- isolates %>% group_by(region) %>% summarise(n = n(), n_strain = n_distinct(Strain))
byStatestbl <- isolates %>% filter(region=='USA') %>% group_by(US_state) %>% summarise(n = n(), n_strain = n_distinct(Strain))

# by region/country:
byRegion <- byRegiontbl %>%
  filter(region != 'NA') %>%
  ggplot() +
  geom_bar(aes(x = reorder(region, n), y = n), 
           stat = 'identity', alpha=0.8)  +
  geom_label(aes(x = reorder(region, n), y = n, label = n), alpha=0.5, hjust=0.6)+
  labs(x='Region', y = 'Number of Isolates') +
  coord_flip() 
# byRegion


# by US states:
byState <- byStatestbl %>% filter(US_state != 'unknown') %>%
  ggplot() +
  geom_bar(aes(x = reorder(US_state, n), y = n), 
           stat = 'identity', alpha=0.8)  +
  labs(x='US States', y = 'Number of Isolates') +
  coord_flip() +
  theme(axis.text = element_text(size = 7))
# byState

grid.arrange(byRegion, byState, ncol=2)
# , top=textGrob("Figure __: Number of Isolates by Region and US States (NA removed)"))

```

Since we're only looking at the high level year over year trend, we omitted the second half of year 2010 (from 05-12-2010 to 12-31-2010) and only include data from 2011 in the following exploratory analysis regading location. In addition, since most of the states only have a relatively small number of isolates, I only included the top 10 states (CA, NY, WA, PA, OH, TX, FL, MI, WI, NC) in Figure __.

By looking at total number of isolates over time in figure __ , we found that the number starts to increase in 2013 and remains high until 2019 and dropped sharply since 2020. From the lower panel of figure __ , we can roughly see that the major contributors of the 'ourbreak' in 2013 and 2014 are USA and Europe and there seems to be a correlation between the two regions, especially since 2020. It might be of interest to investigate if the outbreaks in US and Europe have the same source in the future analysis.


```{r by year and region}
# Add year_grp to differentiate before and after 2010 (the actual cut-off should be May 2010 though)
isolates <- isolates %>% mutate(year = (substr(Collection.date,1,4)),
                                year_grp = ifelse(year<=2010, 'prior2010', 'post2010'))

# Isolates over year since 2010:
fig_byregion <- isolates %>% 
  group_by(region,year_grp, year) %>% 
  summarise(n = n(), n_strain = n_distinct(Strain)) %>%
  filter(region != 'NA' & !is.na(year) & year_grp == 'post2010') %>%
  ggplot() +
  geom_bar(aes(x = year, y = n, fill=region),
           stat = 'identity', alpha=0.8) +
  labs(x='Collection Year', y = 'Number of Isolates',  title='Number of Isolates Over Year by Region')

# YoY trend by region
fig_yoybyregion <- isolates %>% 
  group_by(region,year_grp, year) %>% 
  summarise(n = n(), n_strain = n_distinct(Strain)) %>%
  filter(region != 'NA' & !is.na(year) & year_grp == 'post2010') %>%
  ggplot() +
  geom_line(aes(x=year, y = n, group = region, color=region)) +
  geom_point(aes(x=year, y = n, group = region, color=region)) +
  labs(x='Collection Year', y = 'Number of Isolates', title='Year over Year Trend by Region')

grid.arrange(fig_byregion, fig_yoybyregion, nrow=2)
# , top=textGrob("Figure __: Number of Isolates by Region (NA removed)"))



```


Drilling down to the US state level, we can tell from the top panel of Figure __ that California has the most number of isolates from year 2012 to 2016. Starting from 2018, the distribution became relatively even among different states. The bottom panel shows California experienced the highest number of isolates from 2012 to 2016. Another trend that is worth to note is that Washington and Texas seemed to had an outbreak in year of 2015 with similar trend; after 2 years Pennsylvania experienced an outbreak in 2017. In the future analysis, we could potentially investigate the cases similarities among the mentioned states.

```{r}
# YoY trend by states
highest_state <- byStatestbl %>% arrange(desc(n)) %>% slice_max(n=11, order_by = n) %>% select(US_state)


fig_states_bar<- isolates %>%
  filter(region=='USA' &US_state != 'unknown' & !is.na(year) & year_grp == 'post2010' 
         & US_state %in% highest_state$US_state) %>%
  group_by(US_state,year_grp, year) %>% 
  summarise(n = n(), n_strain = n_distinct(Strain)) %>%
  ggplot() +
  geom_bar(aes(x = year, y = n, fill=US_state),
           stat = 'identity', alpha=0.8) +
  labs(x='Collection Year', y = 'Number of Isolates',  title='Number of Isolates Over Year by States')

fig_states_line <- isolates %>% 
  filter(region=='USA' &US_state != 'unknown' & !is.na(year) & year_grp == 'post2010' 
         & US_state %in% highest_state$US_state) %>%
  group_by(US_state,year_grp, year) %>% 
  summarise(n = n(), n_strain = n_distinct(Strain)) %>%
  ggplot() +
  geom_line(aes(x=year, y = n, group = US_state, color=US_state)) +
  geom_point(aes(x=year, y = n, group = US_state, color=US_state)) +
  labs(x='Collection Year', y = 'Number of Isolates', title='Year over Year Trend by States')

grid.arrange(fig_states_bar, fig_states_line, nrow=2)
# , top=textGrob("Figure __: Number of Isolates by US States (NA removed)"))
```


# Missing pattern for isolation source:

```{r Garys code, results=FALSE}
# Gary's code:
#Load Libraries
# library(RecordLinkage)
library(lubridate)
library(tidyverse)
# library(stringdist)
library(forcats)

#Load Dataset
# isolates <- read.csv("/Users/garyzhou/Downloads/isolates-2.csv")

#Explore Isolation Source
str(isolates)
length(unique(isolates$Isolation.source))

#Sort by Freq of Isolation Source
freq_isol <- isolates %>% group_by(Isolation.source) %>% summarise(freq = n()) %>% arrange(desc(freq))
head(as.data.frame(freq_isol), n=30)

#Find string matches using grepl
unique_isol_source <- unique(isolates$Isolation.source)
test_iso <- isolates$Isolation.source

#Cases with just Beef and no Chicken or Pork
beef_new <- grep("beef", unique_isol_source, ignore.case=TRUE, value=TRUE)
beef_no_chick_pork <- c(grep("chicken", beef_new, ignore.case=TRUE, value=TRUE), grep("pork", beef_new, ignore.case=TRUE, value=TRUE))
beef_final <- beef_new[!beef_new %in% beef_no_chick_pork]

#Cases with just Chicken and no Beef or Pork
chicken_new <- grep("chicken", unique_isol_source, ignore.case=TRUE, value=TRUE)
chicken_no_beef_pork <- c(grep("beef", chicken_new, ignore.case=TRUE, value=TRUE), grep("pork", chicken_new, ignore.case=TRUE, value=TRUE))
chicken_final <- chicken_new[!chicken_new %in% chicken_no_beef_pork]

#Soil
soil_new <- grep("soil", unique_isol_source, ignore.case=TRUE, value=TRUE)[-1]

#Pork with no chicken or beef
pork <- grep("pork", unique_isol_source, ignore.case=TRUE, value=TRUE)
pork_no_chick_beef <- unique(c(grep("chicken", pork, ignore.case=TRUE, value=TRUE), grep("beef", pork, ignore.case=TRUE, value=TRUE)))
pork_final <- pork[!pork %in% pork_no_chick_beef]

#Egg
grep("egg", unique_isol_source, ignore.case=TRUE, value=TRUE)

testt_iso <- fct_collapse(test_iso, Missing = c("", "not provided", "not collected", "Not available", "other"),
                          Food = c("food", "Food products"),
                          Blood_Source = c("blood", "Blood, NOS"),
                          Food_Producing_Environment = c("food producing environment surface", "food producing environment", "Food processing environment", "food processing environment"),
                          Environ_Seafood_Processing_or_Equipment = c("Environmental - Seafood processing environment", "Environmental - Seafood Equipment"),
                          Environmental_Swab = c("environmental swab", "swab"),
                          Environment = c("environment", "Environment", "Environ", "environmental"),
                          Sponge = c("sponge", "environmental sponge", "environmental swab sponge"),
                          Clinical = c("clinical", "clinical isolate", "clinical sample"),
                          Milk = c("milk", "Milk filter", "raw milk", "milk filter"),
                          Meat = c("retail meat", "meat"),
                          Human_Source = c("human", "human listeriosis", "patient"),
                          RTE_Food = c("ready to eat food", "RTE Product"),
                          Ice_Cream = grep("ice cream", unique_isol_source, ignore.case=TRUE, value=TRUE),
                          Avocado_or_Guac = c(grep("avocado", unique_isol_source, ignore.case=TRUE, value=TRUE), "guacamole"),
                          Cheese = grep("cheese", unique_isol_source, ignore.case=TRUE, value=TRUE),
                          Beef = beef_final,
                          Soil = soil_new,
                          Pork = c(pork_final, "ham"),
                          Salmon = c("smoked salmon", "salmon", "Smoked salmon"),
                          Peach = c("peach", "white peach"),
                          Salami_Source = c("Salami", "salami paste production"),
                          Deli_Source = c("retail deli", "drain-deli", "deli meat"),
                          Cow_Feces = c("feces cow", "Cow feces"),
                          CSF = c(grep("CSF", unique_isol_source, ignore.case=TRUE, value=TRUE), "cerebrospinal fluid", "Cerebral spinal fluid"), #CSF and blood were grouped as CSF
                          Chicken = chicken_final)

#Look at unique isolation sources in descending order
head(sort(table(testt_iso), decreasing=TRUE), n=100)
sum(head(sort(table(testt_iso), decreasing=TRUE), n=15)) #75% of data in first 15 levels


# End of Gary's code

```


Since the study will be aiming at classifying isolation source and we will be predicting the unidentified source, we should look at the missing patterns between the missing group and non-missing group. Among the 37629 isolates, there are 33289 having source identified and 4340 have missing source.  We stratified the data set on missing source group and evaluated differences in region, states, and minimum SNP distance to different and same isolation type. Table One result shows that among different regions, Europe and Asia are more likely to have missing sources. Within the US, most of the missing sources came from isolates that don't have a granular state information. In addition, it is worth notice that the average minimum SNP distance to the same isolation type is significantly different between the two groups, where missing-source group has a higher Min.same (7.00) than that of non-missing group (4.96). 

```{r Missing source patterns}
# tmp <- data.frame(test_iso, testt_iso)
# tmp <- tmp %>% mutate(missing= ifelse(is.na(testt_iso), 1,0))
# tmp$isolate_org <- isolates$Isolation.source

isolates <- isolates %>% 
  mutate(testt_iso, 
         missing_source = ifelse(is.na(testt_iso) | testt_iso=='Missing', 1,0))

# CTO <- CreateTableOne(data=isolates, vars=c('region','US_state', 'Min.diff','Min.same'), strata ='missing_source')
CTO <- CreateTableOne(data=isolates, vars=c('region', 'Min.diff','Min.same'), strata ='missing_source')
# write.csv(CTO_kable,"CTO.csv", row.names = FALSE)

# CTO_kable <- kableone(CTO, caption='Variable Comparison by Sissing Source')  

kableone(CTO, caption='Variable Comparison by Sissing Source')  %>% kable_styling()

```



